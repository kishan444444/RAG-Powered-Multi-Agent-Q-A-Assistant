# 🧠 RAG-Powered Multi-Agent Q\&A Assistant

A Streamlit-based web application that leverages LangChain, FAISS, and Groq LLMs to enable users to:

* Upload PDF documents.
* Ask questions based on the content.
* Receive answers extracted from the document or external tools (e.g., calculator, dictionary, or DuckDuckGo search).
* View which tools were used, retrieved context, and the final answer.

---

## 🏗️ Architecture Overview

* **Frontend**: Built with Streamlit for an interactive user interface.
* **Backend**:

  * **PDF Processing**: Utilizes `PyMuPDF` to extract text from uploaded PDFs.
  * **Text Splitting**: Employs `CharacterTextSplitter` to divide text into manageable chunks.
  * **Embeddings**: Uses `SentenceTransformer` for generating embeddings.
  * **Vector Store**: Implements FAISS for efficient similarity search.
  * **RetrievalQA Chain**: Constructs a `RetrievalQA` chain using LangChain for document-based question answering.
  * **Tools**:

    * **Calculator**: Evaluates mathematical expressions using `simpleeval`.
    * **Dictionary**: Provides word definitions via `PyDictionary`.
    * **DuckDuckGo Search**: Fetches real-time information from the web.
  * **Agent**: Initializes a LangChain `ZERO_SHOT_REACT_DESCRIPTION` agent that selects the appropriate tool based on the user's query.

---

## 🔑 Key Design Choices

* **Modular Design**: Encapsulates core functionalities within a `Utils` class for maintainability and scalability.
* **Tool Integration**: Leverages LangChain's `Tool` abstraction to seamlessly integrate various utilities.
* **Contextual Awareness**: Combines document content with external information sources to provide comprehensive answers.
* **Error Handling**: Implements custom exception handling and logging for robust error tracking.

---

## 🚀 Getting Started

### Prerequisites

* Python 3.8 or higher
* [Groq API Key](https://groq.com/)

### Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/kishan444444/RAG-Powered-Multi-Agent-Q-A-Assistant.git
   cd RAG-Powered-Multi-Agent-Q-A-Assistant
   ```

2. **Create a virtual environment** (optional but recommended):

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install the required packages**:

   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**:

   Create a `.env` file in the project root directory and add your Groq API key:

   ```env
   GROQ_API_KEY=your_groq_api_key_here
   ```

### Running the Application

```bash
streamlit run app.py
```

---

## 🧪 Usage

1. **Upload a PDF**: Use the file uploader in the Streamlit interface to upload your PDF document.
2. **Ask a Question**: 

" 1.Summarize the conclusion of this document."

" 2.What is 256 * 3?"

" 3.Define 'neural network'."

" 4.What is the latest news on AI regulation?"



3. **View Results**:

   * **Tools Used**: Displays which tools were utilized to answer your question.
   * **Retrieved Context**: Shows the context snippets retrieved from the document or external sources.
   * **Final Answer**: Presents the answer generated by the LLM agent.

---

## 📁 Project Structure

```
.
├── app.py
├── requirements.txt
├── .env
├── src/
│   └── llm_agent_project/
│       ├── utils/
│       │   └── utils.py
│       ├── exception.py
│       └── logger.py
└── README.md
```

---

## 📄 License

This project is licensed under the MIT License.

---

## 👤 Author

Developed by [Kishan](https://github.com/kishan444444)

For any inquiries or contributions, feel free to reach out or submit a pull request.


